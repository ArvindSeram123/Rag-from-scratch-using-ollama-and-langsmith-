{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a1a553b-4ee5-4faa-b0e5-c6d5bca1e112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (0.3.34)\n",
      "Requirement already satisfied: langchain_core in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (0.3.77)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langchain) (0.4.32)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langchain) (2.0.12)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langchain_core) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langchain_core) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langchain_core) (4.12.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langchain_core) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain_core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.104.2 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langchain_openai) (2.1.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (0.10.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.2.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2025.7.34)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.104.2->langchain_openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain_openai langchain_core python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b060828f-c71e-45c1-8265-34389bac2ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-ollama in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.20 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langchain-ollama) (0.3.77)\n",
      "Requirement already satisfied: ollama<1,>=0.3.0 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langchain-ollama) (0.5.4)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.20->langchain-ollama) (0.4.32)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.20->langchain-ollama) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.20->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.20->langchain-ollama) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.20->langchain-ollama) (4.12.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.20->langchain-ollama) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.20->langchain-ollama) (2.10.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (0.27.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (1.3.0)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (2.27.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (2.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\user\\miniconda3\\envs\\proj\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.20->langchain-ollama) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07b17026-d7bd-41e2-a7cf-ed16dffa45c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66160c38-d957-4a67-bc5b-602368f27652",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOllama(model=\"gpt-oss:120b-cloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85754a2a-332d-437f-b061-a295c91a346d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Summary of the speech**\n",
      "\n",
      "The speaker reminds the audience that, even though each person may feel like a tiny “speck of ocean,” they are an essential part of a vast, interconnected whole. By acknowledging our modest beginnings and the challenges we face, we can find strength in collective purpose and perseverance. The speech emphasizes that every small action contributes to larger change, encouraging listeners to embrace their unique role, stay resilient, and trust that their contributions—no matter how modest—help shape a brighter, more united future.\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Respond based only on the context.\"),\n",
    "    (\"user\", \"Question: {question}\\nContext: {context}\")\n",
    "])\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# Example data\n",
    "question = \"Can you summarize the speech?\"\n",
    "context = \"\"\"Even though you are only a very small speck of ocean... (your full text)\"\"\"\n",
    "\n",
    "print(chain.invoke({\"question\": question, \"context\": context}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "636903ed-297d-4dcb-8d78-1f2628c49182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like the full text of the speech didn’t come through—only the opening phrase “Even though you are only a very small speck of ocean…” was included. To identify the key messages accurately, I’d need the complete speech (or at least the main sections you’d like summarized). Could you please provide the full text or the portions you’d like me to analyze? Once I have that, I’ll be able to pull out the central themes and key messages for you.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 1. Load your text (here directly, but can be files too)\n",
    "speech = \"\"\"Even though you are only a very small speck of ocean...\n",
    "(put full text or multiple docs here)\"\"\"\n",
    "\n",
    "docs = [Document(page_content=speech)]\n",
    "\n",
    "# 2. Split into chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "# 3. Embed & store in Chroma\n",
    "embedding = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = Chroma.from_documents(chunks, embedding)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 4. RAG prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Answer based only on the context.\"),\n",
    "    (\"user\", \"Question: {question}\\nContext: {context}\")\n",
    "])\n",
    "\n",
    "model = ChatOllama(model=\"gpt-oss:120b-cloud\")   # local model\n",
    "parser = StrOutputParser()\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# 5. Query\n",
    "query = \"What are the key messages of the speech?\"\n",
    "docs_context = retriever.get_relevant_documents(query)\n",
    "context = \"\\n\".join([d.page_content for d in docs_context])\n",
    "\n",
    "print(chain.invoke({\"question\": query, \"context\": context}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27287dc8-e919-475a-9ed0-021fff89fa67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’d be happy to pull out the key messages for you, but I need the full text of the speech in order to do that. Could you please paste the complete speech (or the portion you’d like summarized) here? Once I have it, I’ll identify the main points and themes for you.\n"
     ]
    }
   ],
   "source": [
    "# Direct LLM call without retrieval\n",
    "question = \"What are the key messages of the speech?\"\n",
    "\n",
    "context = \"\"\"Even though you are only a very small speck of ocean...\n",
    "(put full speech here)\"\"\"\n",
    "\n",
    "print(chain.invoke({\"question\": question, \"context\": context}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5873239e-cabf-4301-b64d-edb38a2e3e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m happy to help pull out the key messages, but I’ll need the full text of the speech (or the portions you’d like summarized) in order to do that. Could you please paste the speech here? Once I have it, I can identify its main points for you.\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the key messages of the speech?\"\n",
    "docs_context = retriever.get_relevant_documents(query)\n",
    "\n",
    "# Concatenate top chunks as context\n",
    "rag_context = \"\\n\".join([d.page_content for d in docs_context])\n",
    "\n",
    "print(chain.invoke({\"question\": query, \"context\": rag_context}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
